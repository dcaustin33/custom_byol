{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df9afd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook BYOL.ipynb to script\n",
      "[NbConvertApp] Writing 2969 bytes to BYOL.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da2986/anaconda3/lib/python3.9/site-packages/pl_bolts/utils/warnings.py:30: UserWarning: You want to use `gym` which is not installed yet, install it with `pip install gym`.\n",
      "  stdout_func(\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script BYOL.ipynb\n",
    "import BYOL\n",
    "import torch\n",
    "import time\n",
    "from pretrain_dataloader import *\n",
    "from lars import LARSWrapper\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "from utils import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.enabled = True\n",
    "import copy\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b3f093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "args = return_default_args()\n",
    "train_loader = prepare_cifar_train_loader(args)\n",
    "online = BYOL.BYOL_module().to('cuda').to(memory_format=torch.channels_last)\n",
    "target = copy.deepcopy(online).to('cuda').to(memory_format=torch.channels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ee4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "            {\"name\": \"backbone\", \"params\": online.network.parameters()},\n",
    "            {\n",
    "                \"name\": \"classifier\",\n",
    "                \"params\": online.classifier.parameters(),\n",
    "                \"lr\": args.classifier_lr,\n",
    "                \"weight_decay\": args.classifier_weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"momentum_classifier\",\n",
    "                \"params\": target.classifier.parameters(),\n",
    "                \"lr\": args.classifier_lr,\n",
    "                \"weight_decay\": args.classifier_weight_decay,\n",
    "            },\n",
    "            {'params': online.projector.parameters()},\n",
    "            {'params':online.predictor.parameters(),}\n",
    "        ]\n",
    "\n",
    "\n",
    "opt = torch.optim.SGD(params, lr = .3, weight_decay = 1.5e-5, momentum = .9)\n",
    "opt = LARSWrapper(opt, clip = True, exclude_bias_n_norm = True, eta = .001)\n",
    "schedule = LinearWarmupCosineAnnealingLR(\n",
    "                    opt,\n",
    "                    warmup_epochs= 10 * 195,\n",
    "                    max_epochs= 195 * 200,\n",
    "                    warmup_start_lr=3e-05,\n",
    "                    eta_min=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817d2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(data, online, target, temporal_ensembling):\n",
    "    step_metrics = {}\n",
    "    \n",
    "    online1 = online(data[1][0])\n",
    "    online2 = online(data[1][1])\n",
    "    target1 = target.momentum_forward(data[1][0])\n",
    "    target2 = target.momentum_forward(data[1][1])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        average = (target1['z'] + target2['z']) / torch.tensor(2, device = device)\n",
    "        temporal = temporal_ensembling[data[0]].to(device)\n",
    "        temp_average = (temporal[:, 0, :] + temporal[:, 1, :]) / 2\n",
    "\n",
    "        final_average = (temp_average + average) / 2\n",
    "        temporal_ensembling[data[0], 0, :] = temporal_ensembling[data[0], 0, :] * .75 + .25 * target1['z'].cpu()\n",
    "        temporal_ensembling[data[0], 1, :] = temporal_ensembling[data[0], 1, :] * .75 + .25 * target2['z'].cpu()\n",
    "    \n",
    "    #byol_loss\n",
    "    step_metrics[\"byol_loss\"] = byol_loss_func(online1['p'], final_average)\n",
    "    step_metrics[\"byol_loss\"] += byol_loss_func(online2['p'], final_average)\n",
    "    \n",
    "    #cross entropy loss\n",
    "    step_metrics[\"online_cross_entropy_loss\"] = F.cross_entropy(online1['logits'], data[2], ignore_index=-1)\n",
    "    step_metrics[\"momentum_cross_entropy_loss\"] = F.cross_entropy(target1['logits'], data[2], ignore_index=-1)\n",
    "    \n",
    "    #accuracy of predictions\n",
    "    _, predicted = torch.max(online1['logits'], 1)\n",
    "    step_metrics[\"online_acc1\"] = (predicted == data[2]).sum()\n",
    "    _, predicted = torch.max(target1['logits'], 1)\n",
    "    step_metrics[\"target_acc1\"] = (predicted == data[2]).sum()\n",
    "    \n",
    "    _, pred = online1['logits'].topk(5)\n",
    "    data[2] = data[2].unsqueeze(1).expand_as(pred)\n",
    "    step_metrics[\"online_acc5\"] = (data[2] == pred).any(dim = 1).sum()\n",
    "    _, pred = target1['logits'].topk(5)\n",
    "    step_metrics[\"target_acc5\"] = (data[2] == pred).any(dim = 1).sum()\n",
    "                   \n",
    "        \n",
    "    \n",
    "    \n",
    "    #metrics to track\n",
    "    with torch.no_grad():\n",
    "        online1p_softmax = F.softmax(online1['p'], dim = 1)\n",
    "        online2p_softmax = F.softmax(online2['p'], dim = 1)\n",
    "        online1rep_softmax = F.softmax(online1['Representation'], dim = 1)\n",
    "        online2rep_softmax = F.softmax(online2['Representation'], dim = 1)\n",
    "        online1z_softmax = F.softmax(online1['z'], dim = 1)\n",
    "        online2z_softmax = F.softmax(online2['z'], dim = 1)\n",
    "        \n",
    "        target1z_softmax = F.softmax(target1['z'], dim = 1)\n",
    "        target2z_softmax = F.softmax(target1['z'], dim = 1)\n",
    "        target1rep_softmax = F.softmax(target1['Representation'], dim = 1)\n",
    "        target2rep_softmax = F.softmax(target2['Representation'], dim = 1)\n",
    "        \n",
    "        \n",
    "        cross_entropy = F.cross_entropy(online1p_softmax, target2z_softmax, ignore_index=-1) + F.cross_entropy(online2p_softmax, target1z_softmax, ignore_index=-1)\n",
    "        l1_dist = F.l1_loss(online1['p'], target2['z']) + F.l1_loss(online2['p'], target1['z'])\n",
    "        l2_dist = F.mse_loss(online1['p'], target2['z']) + F.mse_loss(online2['p'], target1['z'])\n",
    "        smooth_l1 = F.smooth_l1_loss(online1['p'], target2['z']) + F.smooth_l1_loss(online2['p'], target1['z'])\n",
    "        kl_div = F.kl_div(online1p_softmax, target2z_softmax) + F.kl_div(online2p_softmax, target1z_softmax)\n",
    "\n",
    "        representation_l1 = F.l1_loss(online1['Representation'], target2['Representation']) + F.l1_loss(online2['Representation'], target1['Representation'])\n",
    "        representation_l2 = F.mse_loss(online1['Representation'], target2['Representation']) + F.mse_loss(online2['Representation'], target1['Representation'])\n",
    "        representation_cross_entropy = F.cross_entropy(online1rep_softmax, target2rep_softmax, ignore_index=-1) + F.cross_entropy(online2rep_softmax, target1rep_softmax, ignore_index=-1)\n",
    "        representation_kl = F.kl_div(online1rep_softmax, target2rep_softmax) + F.kl_div(online2rep_softmax, target1rep_softmax)\n",
    "        representation_cos_sim = F.cosine_similarity(online1['Representation'], target2['Representation']) + F.cosine_similarity(online2['Representation'], target1['Representation'])\n",
    "\n",
    "        projection_l1 = F.l1_loss(online1['z'], target2['z']) + F.l1_loss(online2['z'], target1['z'])\n",
    "        projection_l2 = F.mse_loss(online1['z'], target2['z']) + F.mse_loss(online2['z'], target1['z'])\n",
    "        projection_cross_entropy = F.cross_entropy(online1z_softmax, target2z_softmax, ignore_index=-1) + F.cross_entropy(online2z_softmax, target1z_softmax, ignore_index=-1)\n",
    "        projection_kl = F.kl_div(online1z_softmax, target2z_softmax) + F.kl_div(online2z_softmax, target1z_softmax)\n",
    "        projection_cos_sim = F.cosine_similarity(online1['z'], target2['z']) + F.cosine_similarity(online2['z'], target1['z'])\n",
    "\n",
    "        momentum_projection_cos_sim = F.cosine_similarity(target1['z'], target2['z'])\n",
    "        momentum_representation_cos_sim = F.cosine_similarity(target1['Representation'], target2['Representation'])\n",
    "        momentum_representation_l2 =  F.mse_loss(target1['Representation'], target2['Representation'])\n",
    "        momentum_projection_l2 =  F.mse_loss(target1['z'], target2['z'])\n",
    "\n",
    "        online_projection_cos_sim = F.cosine_similarity(online1['z'], online2['z'])\n",
    "        online_representation_cos_sim = F.cosine_similarity(online1['Representation'], online2['Representation'])\n",
    "        online_representation_l2 =  F.mse_loss(online1['Representation'], online2['Representation'])\n",
    "        online_projection_l2 =  F.mse_loss(online1['z'], online2['z'])\n",
    "        \n",
    "        online_representation_std = torch.mean(torch.std(online1['Representation']))\n",
    "        online_projection_std = torch.mean(torch.std(online1['z']))\n",
    "        online_prediction_std = torch.mean(torch.std(online1['p']))\n",
    "        target_representation_std = torch.mean(torch.std(target1['Representation']))\n",
    "        target_projection_std = torch.mean(torch.std(target1['z']))\n",
    "\n",
    "        step_metrics.update({\n",
    "            \"train_feats_cross_entropy\": cross_entropy,\n",
    "            \"train_feats_l1_dist\": l1_dist,\n",
    "            \"train_feats_l2_dist\": l2_dist,\n",
    "            \"train_feats_smooth_l1\": smooth_l1,\n",
    "            \"train_feats_kl_div\": kl_div,\n",
    "            \"representation_l1\": representation_l1,\n",
    "            \"representation_l2\": representation_l1,\n",
    "            \"representation_cross_entropy\": representation_cross_entropy,\n",
    "            \"representation_kl\": representation_kl,\n",
    "            \"representation_cos_sim\": representation_cos_sim.mean(),\n",
    "            \"projection_l1\": projection_l1,\n",
    "            \"projection_l2\": projection_l2,\n",
    "            \"projection_cross_entropy\": projection_cross_entropy,\n",
    "            \"projection_kl\": projection_kl,\n",
    "            \"projection_cos_sim\": projection_cos_sim.mean(),\n",
    "            \"momentum_projection_cos_sim\": momentum_projection_cos_sim.mean(),\n",
    "            \"momentum_representation_cos_sim\": momentum_representation_cos_sim.mean(),\n",
    "            \"momentum_representation_l2\": momentum_representation_l2,\n",
    "            \"momentum_representation_l2\": momentum_projection_l2,\n",
    "            \"online_projection_cos_sim\": online_projection_cos_sim.mean(),\n",
    "            \"online_representation_cos_sim\": online_representation_cos_sim.mean(),\n",
    "            \"online_representation_l2\": online_representation_l2,\n",
    "            \"online_projection_l2\": online_projection_l2,\n",
    "            \"online_representation_std\": online_representation_std,\n",
    "            \"online_projection_std\": online_projection_std,\n",
    "            \"online_prediction_std\": online_prediction_std,\n",
    "            \"target_representation_std\": target_representation_std,\n",
    "            \"target_projection_std\": target_projection_std,\n",
    "            })\n",
    "    return step_metrics[\"byol_loss\"] + step_metrics[\"online_cross_entropy_loss\"] + \\\n",
    "            step_metrics[\"momentum_cross_entropy_loss\"], step_metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bfd586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdcaustin33\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/da2986/custom_byol/wandb/run-20220424_144856-1n2uylvg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dcaustin33/custom_byol/runs/1n2uylvg\" target=\"_blank\">BYOL - Temp Ensemble .75 Old 99 Momentum</a></strong> to <a href=\"https://wandb.ai/dcaustin33/custom_byol\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log = True\n",
    "name = 'BYOL - Temp Ensemble .75 Old 99 Momentum'\n",
    "if log:\n",
    "    wandb.init(config = args.__dict__, name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5e40b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da2986/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:2886: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 56.514204025268555 tensor(11.7800, device='cuda:0', grad_fn=<DivBackward0>) tensor(2.6434, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0194, device='cuda:0') tensor(0.0177, device='cuda:0')\n",
      "1 56.81884527206421 tensor(10.3899, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.5560, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0375, device='cuda:0') tensor(0.0354, device='cuda:0')\n",
      "2 56.344401597976685 tensor(9.5313, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.9106, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0532, device='cuda:0') tensor(0.0489, device='cuda:0')\n",
      "3 57.230048418045044 tensor(9.0621, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6225, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0657, device='cuda:0') tensor(0.0635, device='cuda:0')\n",
      "4 56.36947011947632 tensor(8.7656, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5016, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0780, device='cuda:0') tensor(0.0755, device='cuda:0')\n",
      "5 56.41965126991272 tensor(8.5543, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4448, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0869, device='cuda:0') tensor(0.0844, device='cuda:0')\n",
      "6 57.22948670387268 tensor(8.3754, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4151, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0993, device='cuda:0') tensor(0.0973, device='cuda:0')\n",
      "7 56.99432706832886 tensor(8.2225, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3923, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1098, device='cuda:0') tensor(0.1079, device='cuda:0')\n",
      "8 56.64215397834778 tensor(8.0831, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1187, device='cuda:0') tensor(0.1170, device='cuda:0')\n",
      "9 56.76206183433533 tensor(7.9609, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3600, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1296, device='cuda:0') tensor(0.1285, device='cuda:0')\n",
      "10 56.865790367126465 tensor(7.8352, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3464, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1368, device='cuda:0') tensor(0.1368, device='cuda:0')\n",
      "11 57.68516778945923 tensor(7.7138, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3348, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1447, device='cuda:0') tensor(0.1446, device='cuda:0')\n",
      "12 55.93494915962219 tensor(7.6501, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1493, device='cuda:0') tensor(0.1506, device='cuda:0')\n",
      "13 56.7338330745697 tensor(7.5317, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1609, device='cuda:0') tensor(0.1610, device='cuda:0')\n",
      "14 56.44424533843994 tensor(7.4382, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1697, device='cuda:0') tensor(0.1701, device='cuda:0')\n",
      "15 55.81049299240112 tensor(7.3589, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1730, device='cuda:0') tensor(0.1739, device='cuda:0')\n",
      "16 56.53442430496216 tensor(7.2540, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1833, device='cuda:0') tensor(0.1829, device='cuda:0')\n",
      "17 56.64327621459961 tensor(7.1659, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2869, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1909, device='cuda:0') tensor(0.1908, device='cuda:0')\n",
      "18 56.75146698951721 tensor(7.0974, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1938, device='cuda:0') tensor(0.1943, device='cuda:0')\n",
      "19 55.77839207649231 tensor(7.0078, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2024, device='cuda:0') tensor(0.2018, device='cuda:0')\n",
      "20 57.219767570495605 tensor(6.9301, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2775, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2081, device='cuda:0') tensor(0.2082, device='cuda:0')\n",
      "21 57.17934012413025 tensor(6.8329, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2176, device='cuda:0') tensor(0.2181, device='cuda:0')\n",
      "22 56.34932041168213 tensor(6.7446, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2246, device='cuda:0') tensor(0.2269, device='cuda:0')\n",
      "23 56.749489068984985 tensor(6.6743, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2278, device='cuda:0') tensor(0.2298, device='cuda:0')\n",
      "24 56.00192356109619 tensor(6.5827, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2392, device='cuda:0') tensor(0.2415, device='cuda:0')\n",
      "25 56.38102674484253 tensor(6.5285, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2707, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2417, device='cuda:0') tensor(0.2440, device='cuda:0')\n",
      "26 56.127800941467285 tensor(6.4624, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2492, device='cuda:0') tensor(0.2520, device='cuda:0')\n",
      "27 56.26202893257141 tensor(6.3941, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2555, device='cuda:0') tensor(0.2563, device='cuda:0')\n",
      "28 56.62428283691406 tensor(6.3242, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2629, device='cuda:0') tensor(0.2639, device='cuda:0')\n",
      "29 56.60709023475647 tensor(6.2716, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2666, device='cuda:0') tensor(0.2692, device='cuda:0')\n",
      "30 56.8893666267395 tensor(6.2256, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2698, device='cuda:0') tensor(0.2733, device='cuda:0')\n",
      "31 56.12193417549133 tensor(6.1708, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2736, device='cuda:0') tensor(0.2756, device='cuda:0')\n",
      "32 56.20248603820801 tensor(6.1194, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2795, device='cuda:0') tensor(0.2816, device='cuda:0')\n",
      "33 56.9345018863678 tensor(6.0716, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2872, device='cuda:0') tensor(0.2892, device='cuda:0')\n",
      "34 56.625245094299316 tensor(6.0145, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2900, device='cuda:0') tensor(0.2927, device='cuda:0')\n",
      "35 56.41498637199402 tensor(5.9810, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2921, device='cuda:0') tensor(0.2963, device='cuda:0')\n",
      "36 55.73771858215332 tensor(5.9321, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2969, device='cuda:0') tensor(0.3017, device='cuda:0')\n",
      "37 56.29203248023987 tensor(5.8798, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3038, device='cuda:0') tensor(0.3064, device='cuda:0')\n",
      "38 55.98613238334656 tensor(5.8157, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2651, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3083, device='cuda:0') tensor(0.3137, device='cuda:0')\n",
      "39 56.29304528236389 tensor(5.7793, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3126, device='cuda:0') tensor(0.3179, device='cuda:0')\n",
      "40 57.05803465843201 tensor(5.7302, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3155, device='cuda:0') tensor(0.3195, device='cuda:0')\n",
      "41 57.496169328689575 tensor(5.7019, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3197, device='cuda:0') tensor(0.3251, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 56.550097703933716 tensor(5.6658, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3271, device='cuda:0') tensor(0.3325, device='cuda:0')\n",
      "43 56.17641830444336 tensor(5.6385, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3261, device='cuda:0') tensor(0.3301, device='cuda:0')\n",
      "44 55.895565032958984 tensor(5.5752, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3338, device='cuda:0') tensor(0.3382, device='cuda:0')\n",
      "45 56.13703274726868 tensor(5.5565, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3340, device='cuda:0') tensor(0.3385, device='cuda:0')\n",
      "46 56.07009291648865 tensor(5.5259, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3372, device='cuda:0') tensor(0.3418, device='cuda:0')\n",
      "47 56.094326972961426 tensor(5.5041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3412, device='cuda:0') tensor(0.3453, device='cuda:0')\n",
      "48 56.418185234069824 tensor(5.4647, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3439, device='cuda:0') tensor(0.3488, device='cuda:0')\n",
      "49 56.59595084190369 tensor(5.4388, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3508, device='cuda:0') tensor(0.3540, device='cuda:0')\n",
      "50 56.4171724319458 tensor(5.4052, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3516, device='cuda:0') tensor(0.3549, device='cuda:0')\n",
      "51 56.63851022720337 tensor(5.3497, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3563, device='cuda:0') tensor(0.3625, device='cuda:0')\n",
      "52 56.73223114013672 tensor(5.3229, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3610, device='cuda:0') tensor(0.3650, device='cuda:0')\n",
      "53 56.05607032775879 tensor(5.3026, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3636, device='cuda:0') tensor(0.3687, device='cuda:0')\n",
      "54 56.488921880722046 tensor(5.2701, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3651, device='cuda:0') tensor(0.3684, device='cuda:0')\n",
      "55 56.01884317398071 tensor(5.2517, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3667, device='cuda:0') tensor(0.3710, device='cuda:0')\n",
      "56 56.086851596832275 tensor(5.2396, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3669, device='cuda:0') tensor(0.3717, device='cuda:0')\n",
      "57 56.15086507797241 tensor(5.2033, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3725, device='cuda:0') tensor(0.3781, device='cuda:0')\n",
      "58 55.85168480873108 tensor(5.1598, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3806, device='cuda:0') tensor(0.3846, device='cuda:0')\n",
      "59 55.90868091583252 tensor(5.1578, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3801, device='cuda:0') tensor(0.3848, device='cuda:0')\n",
      "60 56.30582904815674 tensor(5.1288, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2670, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3795, device='cuda:0') tensor(0.3826, device='cuda:0')\n",
      "61 56.540444135665894 tensor(5.1139, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3794, device='cuda:0') tensor(0.3857, device='cuda:0')\n",
      "62 56.31963109970093 tensor(5.0677, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3873, device='cuda:0') tensor(0.3907, device='cuda:0')\n",
      "63 56.04444336891174 tensor(5.0493, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2681, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3919, device='cuda:0') tensor(0.3959, device='cuda:0')\n",
      "64 56.51398539543152 tensor(5.0354, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3902, device='cuda:0') tensor(0.3952, device='cuda:0')\n",
      "65 56.43768787384033 tensor(5.0343, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3896, device='cuda:0') tensor(0.3961, device='cuda:0')\n",
      "66 56.351069688797 tensor(5.0078, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2693, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3919, device='cuda:0') tensor(0.3975, device='cuda:0')\n",
      "67 56.538496255874634 tensor(4.9777, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3962, device='cuda:0') tensor(0.4006, device='cuda:0')\n",
      "68 56.566033124923706 tensor(4.9501, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4000, device='cuda:0') tensor(0.4062, device='cuda:0')\n",
      "69 55.99522042274475 tensor(4.9292, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4050, device='cuda:0') tensor(0.4091, device='cuda:0')\n",
      "70 56.20249819755554 tensor(4.9073, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4041, device='cuda:0') tensor(0.4092, device='cuda:0')\n",
      "71 56.13858962059021 tensor(4.9056, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4062, device='cuda:0') tensor(0.4094, device='cuda:0')\n",
      "72 56.36918330192566 tensor(4.8621, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4058, device='cuda:0') tensor(0.4123, device='cuda:0')\n",
      "73 56.117027759552 tensor(4.8379, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4122, device='cuda:0') tensor(0.4153, device='cuda:0')\n",
      "74 56.33972358703613 tensor(4.8499, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4111, device='cuda:0') tensor(0.4162, device='cuda:0')\n",
      "75 56.55888056755066 tensor(4.8504, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4109, device='cuda:0') tensor(0.4167, device='cuda:0')\n",
      "76 56.058390378952026 tensor(4.8251, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4142, device='cuda:0') tensor(0.4181, device='cuda:0')\n",
      "77 56.430001974105835 tensor(4.7949, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4183, device='cuda:0') tensor(0.4216, device='cuda:0')\n",
      "78 56.27104735374451 tensor(4.7820, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4174, device='cuda:0') tensor(0.4232, device='cuda:0')\n",
      "79 56.174065351486206 tensor(4.7406, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4209, device='cuda:0') tensor(0.4252, device='cuda:0')\n",
      "80 55.93880033493042 tensor(4.7319, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4220, device='cuda:0') tensor(0.4260, device='cuda:0')\n",
      "81 56.19950819015503 tensor(4.7173, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4258, device='cuda:0') tensor(0.4308, device='cuda:0')\n",
      "82 56.469130516052246 tensor(4.7233, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4248, device='cuda:0') tensor(0.4299, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "temporal_ensembling = torch.randn(50001, 2, 256) #in case the indexs are not zero indexed\n",
    "\n",
    "for e in range(200):\n",
    "    metrics = {\n",
    "        \"byol_loss\": 0,\n",
    "        'online_cross_entropy_loss': 0,\n",
    "        'momentum_cross_entropy_loss': 0,\n",
    "        'online_acc1': 0,\n",
    "        'target_acc1': 0,\n",
    "        'online_acc5': 0,\n",
    "        'target_acc5': 0,\n",
    "        \"train_feats_cross_entropy\": 0,\n",
    "        \"train_feats_l1_dist\": 0,\n",
    "        \"train_feats_l2_dist\": 0,\n",
    "        \"train_feats_smooth_l1\": 0,\n",
    "        \"train_feats_kl_div\": 0,\n",
    "        \"representation_l1\": 0,\n",
    "        \"representation_l2\": 0,\n",
    "        \"representation_cross_entropy\": 0,\n",
    "        \"representation_kl\": 0,\n",
    "        \"representation_cos_sim\": 0,\n",
    "        \"projection_l1\": 0,\n",
    "        \"projection_l2\": 0,\n",
    "        \"projection_cross_entropy\": 0,\n",
    "        \"projection_kl\": 0,\n",
    "        \"projection_cos_sim\": 0,\n",
    "        \"momentum_projection_cos_sim\": 0,\n",
    "        \"momentum_representation_cos_sim\": 0,\n",
    "        \"momentum_representation_l2\": 0,\n",
    "        \"momentum_representation_l2\": 0,\n",
    "        \"online_projection_cos_sim\": 0,\n",
    "        \"online_representation_cos_sim\": 0,\n",
    "        \"online_representation_l2\": 0,\n",
    "        \"online_projection_l2\": 0,\n",
    "        \"online_representation_std\": 0,\n",
    "        \"online_projection_std\": 0,\n",
    "        \"online_prediction_std\": 0,\n",
    "        \"target_representation_std\": 0,\n",
    "        \"target_projection_std\": 0,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    total_loss = 0\n",
    "    now = time.time()\n",
    "    for i_, data in enumerate(train_loader):\n",
    "        \n",
    "        with torch.autocast('cuda'):\n",
    "            step += 1\n",
    "            data[0] = data[0].to('cuda')\n",
    "            data[1][0] = data[1][0].to('cuda').to(memory_format=torch.channels_last)\n",
    "            data[1][1] = data[1][1].to('cuda').to(memory_format=torch.channels_last)\n",
    "            data[2] = data[2].to('cuda')\n",
    "            \n",
    "            \n",
    "            loss, step_metrics = training_step(data, online, target, temporal_ensembling)\n",
    "            opt.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            schedule.step()\n",
    "            scaler.update()\n",
    "\n",
    "            update_target_params(online.network.parameters(), target.network.parameters(), .99)\n",
    "            update_target_params(online.projector.parameters(), target.projector.parameters(), .99)\n",
    "                \n",
    "        total_loss += loss\n",
    "        for key in step_metrics:\n",
    "            metrics[key] += step_metrics[key]\n",
    "\n",
    "    print(e, time.time() - now, total_loss / (i_+1), metrics['byol_loss'] / (i_+1), \n",
    "          metrics['online_acc1'] / 50000, metrics['target_acc1'] / 50000)\n",
    "    if log:\n",
    "        i_ += 1\n",
    "        for key in metrics:\n",
    "            if key[-4:-1] == 'acc':\n",
    "                metrics[key] = metrics[key] / 50000\n",
    "            else:\n",
    "                metrics[key] = metrics[key]/i_\n",
    "        wandb.log(metrics)\n",
    "    checkpoint = {\n",
    "    'online': online.state_dict(),\n",
    "    'target': target.state_dict(),\n",
    "    'epoch': e,\n",
    "    'optimizer': opt.optim.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, 'checkpoint.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(online.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26a857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cc9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = return_default_args()\n",
    "train_loader = prepare_cifar_train_loader(args)\n",
    "online = BYOL.BYOL_module().to('cuda').to(memory_format=torch.channels_last)\n",
    "target = copy.deepcopy(online).to('cuda').to(memory_format=torch.channels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "            {\"name\": \"backbone\", \"params\": online.network.parameters()},\n",
    "            {\n",
    "                \"name\": \"classifier\",\n",
    "                \"params\": online.classifier.parameters(),\n",
    "                \"lr\": args.classifier_lr,\n",
    "                \"weight_decay\": args.classifier_weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"momentum_classifier\",\n",
    "                \"params\": target.classifier.parameters(),\n",
    "                \"lr\": args.classifier_lr,\n",
    "                \"weight_decay\": args.classifier_weight_decay,\n",
    "            },\n",
    "            {'params': online.projector.parameters()},\n",
    "            {'params':online.predictor.parameters(),}\n",
    "        ]\n",
    "\n",
    "\n",
    "opt = torch.optim.SGD(params, lr = .3, weight_decay = 1.5e-5, momentum = .9)\n",
    "opt = LARSWrapper(opt, clip = True, exclude_bias_n_norm = True, eta = .001)\n",
    "schedule = LinearWarmupCosineAnnealingLR(\n",
    "                    opt,\n",
    "                    warmup_epochs= 10 * 195,\n",
    "                    max_epochs= 195 * 200,\n",
    "                    warmup_start_lr=3e-05,\n",
    "                    eta_min=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d50f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(data, online, target, temporal_ensembling):\n",
    "    step_metrics = {}\n",
    "    \n",
    "    online1 = online(data[1][0])\n",
    "    online2 = online(data[1][1])\n",
    "    target1 = target.momentum_forward(data[1][0])\n",
    "    target2 = target.momentum_forward(data[1][1])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        average = (target1['z'] + target2['z']) / torch.tensor(2, device = device)\n",
    "        temporal = temporal_ensembling[data[0]].to(device)\n",
    "        temp_average = (temporal[:, 0, :] + temporal[:, 1, :]) / 2\n",
    "\n",
    "        final_average = (temp_average + average) / 2\n",
    "        temporal_ensembling[data[0], 0, :] = temporal_ensembling[data[0], 0, :] * .25 + .75 * target1['z'].cpu()\n",
    "        temporal_ensembling[data[0], 1, :] = temporal_ensembling[data[0], 1, :] * .25 + .75 * target2['z'].cpu()\n",
    "    \n",
    "    #byol_loss\n",
    "    step_metrics[\"byol_loss\"] = byol_loss_func(online1['p'], final_average)\n",
    "    step_metrics[\"byol_loss\"] += byol_loss_func(online2['p'], final_average)\n",
    "    \n",
    "    #cross entropy loss\n",
    "    step_metrics[\"online_cross_entropy_loss\"] = F.cross_entropy(online1['logits'], data[2], ignore_index=-1)\n",
    "    step_metrics[\"momentum_cross_entropy_loss\"] = F.cross_entropy(target1['logits'], data[2], ignore_index=-1)\n",
    "    \n",
    "    #accuracy of predictions\n",
    "    _, predicted = torch.max(online1['logits'], 1)\n",
    "    step_metrics[\"online_acc1\"] = (predicted == data[2]).sum()\n",
    "    _, predicted = torch.max(target1['logits'], 1)\n",
    "    step_metrics[\"target_acc1\"] = (predicted == data[2]).sum()\n",
    "    \n",
    "    _, pred = online1['logits'].topk(5)\n",
    "    data[2] = data[2].unsqueeze(1).expand_as(pred)\n",
    "    step_metrics[\"online_acc5\"] = (data[2] == pred).any(dim = 1).sum()\n",
    "    _, pred = target1['logits'].topk(5)\n",
    "    step_metrics[\"target_acc5\"] = (data[2] == pred).any(dim = 1).sum()\n",
    "                   \n",
    "        \n",
    "    \n",
    "    \n",
    "    #metrics to track\n",
    "    with torch.no_grad():\n",
    "        online1p_softmax = F.softmax(online1['p'], dim = 1)\n",
    "        online2p_softmax = F.softmax(online2['p'], dim = 1)\n",
    "        online1rep_softmax = F.softmax(online1['Representation'], dim = 1)\n",
    "        online2rep_softmax = F.softmax(online2['Representation'], dim = 1)\n",
    "        online1z_softmax = F.softmax(online1['z'], dim = 1)\n",
    "        online2z_softmax = F.softmax(online2['z'], dim = 1)\n",
    "        \n",
    "        target1z_softmax = F.softmax(target1['z'], dim = 1)\n",
    "        target2z_softmax = F.softmax(target1['z'], dim = 1)\n",
    "        target1rep_softmax = F.softmax(target1['Representation'], dim = 1)\n",
    "        target2rep_softmax = F.softmax(target2['Representation'], dim = 1)\n",
    "        \n",
    "        \n",
    "        cross_entropy = F.cross_entropy(online1p_softmax, target2z_softmax, ignore_index=-1) + F.cross_entropy(online2p_softmax, target1z_softmax, ignore_index=-1)\n",
    "        l1_dist = F.l1_loss(online1['p'], target2['z']) + F.l1_loss(online2['p'], target1['z'])\n",
    "        l2_dist = F.mse_loss(online1['p'], target2['z']) + F.mse_loss(online2['p'], target1['z'])\n",
    "        smooth_l1 = F.smooth_l1_loss(online1['p'], target2['z']) + F.smooth_l1_loss(online2['p'], target1['z'])\n",
    "        kl_div = F.kl_div(online1p_softmax, target2z_softmax) + F.kl_div(online2p_softmax, target1z_softmax)\n",
    "\n",
    "        representation_l1 = F.l1_loss(online1['Representation'], target2['Representation']) + F.l1_loss(online2['Representation'], target1['Representation'])\n",
    "        representation_l2 = F.mse_loss(online1['Representation'], target2['Representation']) + F.mse_loss(online2['Representation'], target1['Representation'])\n",
    "        representation_cross_entropy = F.cross_entropy(online1rep_softmax, target2rep_softmax, ignore_index=-1) + F.cross_entropy(online2rep_softmax, target1rep_softmax, ignore_index=-1)\n",
    "        representation_kl = F.kl_div(online1rep_softmax, target2rep_softmax) + F.kl_div(online2rep_softmax, target1rep_softmax)\n",
    "        representation_cos_sim = F.cosine_similarity(online1['Representation'], target2['Representation']) + F.cosine_similarity(online2['Representation'], target1['Representation'])\n",
    "\n",
    "        projection_l1 = F.l1_loss(online1['z'], target2['z']) + F.l1_loss(online2['z'], target1['z'])\n",
    "        projection_l2 = F.mse_loss(online1['z'], target2['z']) + F.mse_loss(online2['z'], target1['z'])\n",
    "        projection_cross_entropy = F.cross_entropy(online1z_softmax, target2z_softmax, ignore_index=-1) + F.cross_entropy(online2z_softmax, target1z_softmax, ignore_index=-1)\n",
    "        projection_kl = F.kl_div(online1z_softmax, target2z_softmax) + F.kl_div(online2z_softmax, target1z_softmax)\n",
    "        projection_cos_sim = F.cosine_similarity(online1['z'], target2['z']) + F.cosine_similarity(online2['z'], target1['z'])\n",
    "\n",
    "        momentum_projection_cos_sim = F.cosine_similarity(target1['z'], target2['z'])\n",
    "        momentum_representation_cos_sim = F.cosine_similarity(target1['Representation'], target2['Representation'])\n",
    "        momentum_representation_l2 =  F.mse_loss(target1['Representation'], target2['Representation'])\n",
    "        momentum_projection_l2 =  F.mse_loss(target1['z'], target2['z'])\n",
    "\n",
    "        online_projection_cos_sim = F.cosine_similarity(online1['z'], online2['z'])\n",
    "        online_representation_cos_sim = F.cosine_similarity(online1['Representation'], online2['Representation'])\n",
    "        online_representation_l2 =  F.mse_loss(online1['Representation'], online2['Representation'])\n",
    "        online_projection_l2 =  F.mse_loss(online1['z'], online2['z'])\n",
    "        \n",
    "        online_representation_std = torch.mean(torch.std(online1['Representation']))\n",
    "        online_projection_std = torch.mean(torch.std(online1['z']))\n",
    "        online_prediction_std = torch.mean(torch.std(online1['p']))\n",
    "        target_representation_std = torch.mean(torch.std(target1['Representation']))\n",
    "        target_projection_std = torch.mean(torch.std(target1['z']))\n",
    "\n",
    "        step_metrics.update({\n",
    "            \"train_feats_cross_entropy\": cross_entropy,\n",
    "            \"train_feats_l1_dist\": l1_dist,\n",
    "            \"train_feats_l2_dist\": l2_dist,\n",
    "            \"train_feats_smooth_l1\": smooth_l1,\n",
    "            \"train_feats_kl_div\": kl_div,\n",
    "            \"representation_l1\": representation_l1,\n",
    "            \"representation_l2\": representation_l1,\n",
    "            \"representation_cross_entropy\": representation_cross_entropy,\n",
    "            \"representation_kl\": representation_kl,\n",
    "            \"representation_cos_sim\": representation_cos_sim.mean(),\n",
    "            \"projection_l1\": projection_l1,\n",
    "            \"projection_l2\": projection_l2,\n",
    "            \"projection_cross_entropy\": projection_cross_entropy,\n",
    "            \"projection_kl\": projection_kl,\n",
    "            \"projection_cos_sim\": projection_cos_sim.mean(),\n",
    "            \"momentum_projection_cos_sim\": momentum_projection_cos_sim.mean(),\n",
    "            \"momentum_representation_cos_sim\": momentum_representation_cos_sim.mean(),\n",
    "            \"momentum_representation_l2\": momentum_representation_l2,\n",
    "            \"momentum_representation_l2\": momentum_projection_l2,\n",
    "            \"online_projection_cos_sim\": online_projection_cos_sim.mean(),\n",
    "            \"online_representation_cos_sim\": online_representation_cos_sim.mean(),\n",
    "            \"online_representation_l2\": online_representation_l2,\n",
    "            \"online_projection_l2\": online_projection_l2,\n",
    "            \"online_representation_std\": online_representation_std,\n",
    "            \"online_projection_std\": online_projection_std,\n",
    "            \"online_prediction_std\": online_prediction_std,\n",
    "            \"target_representation_std\": target_representation_std,\n",
    "            \"target_projection_std\": target_projection_std,\n",
    "            })\n",
    "    return step_metrics[\"byol_loss\"] + step_metrics[\"online_cross_entropy_loss\"] + \\\n",
    "            step_metrics[\"momentum_cross_entropy_loss\"], step_metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd86aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = True\n",
    "name = 'BYOL - Temp Ensemble .25 Old 99 Momentum'\n",
    "if log:\n",
    "    wandb.init(config = args.__dict__, name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc6f25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "temporal_ensembling = torch.randn(50001, 2, 256) #in case the indexs are not zero indexed\n",
    "\n",
    "for e in range(200):\n",
    "    metrics = {\n",
    "        \"byol_loss\": 0,\n",
    "        'online_cross_entropy_loss': 0,\n",
    "        'momentum_cross_entropy_loss': 0,\n",
    "        'online_acc1': 0,\n",
    "        'target_acc1': 0,\n",
    "        'online_acc5': 0,\n",
    "        'target_acc5': 0,\n",
    "        \"train_feats_cross_entropy\": 0,\n",
    "        \"train_feats_l1_dist\": 0,\n",
    "        \"train_feats_l2_dist\": 0,\n",
    "        \"train_feats_smooth_l1\": 0,\n",
    "        \"train_feats_kl_div\": 0,\n",
    "        \"representation_l1\": 0,\n",
    "        \"representation_l2\": 0,\n",
    "        \"representation_cross_entropy\": 0,\n",
    "        \"representation_kl\": 0,\n",
    "        \"representation_cos_sim\": 0,\n",
    "        \"projection_l1\": 0,\n",
    "        \"projection_l2\": 0,\n",
    "        \"projection_cross_entropy\": 0,\n",
    "        \"projection_kl\": 0,\n",
    "        \"projection_cos_sim\": 0,\n",
    "        \"momentum_projection_cos_sim\": 0,\n",
    "        \"momentum_representation_cos_sim\": 0,\n",
    "        \"momentum_representation_l2\": 0,\n",
    "        \"momentum_representation_l2\": 0,\n",
    "        \"online_projection_cos_sim\": 0,\n",
    "        \"online_representation_cos_sim\": 0,\n",
    "        \"online_representation_l2\": 0,\n",
    "        \"online_projection_l2\": 0,\n",
    "        \"online_representation_std\": 0,\n",
    "        \"online_projection_std\": 0,\n",
    "        \"online_prediction_std\": 0,\n",
    "        \"target_representation_std\": 0,\n",
    "        \"target_projection_std\": 0,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    total_loss = 0\n",
    "    now = time.time()\n",
    "    for i_, data in enumerate(train_loader):\n",
    "        \n",
    "        with torch.autocast('cuda'):\n",
    "            step += 1\n",
    "            data[0] = data[0].to('cuda')\n",
    "            data[1][0] = data[1][0].to('cuda').to(memory_format=torch.channels_last)\n",
    "            data[1][1] = data[1][1].to('cuda').to(memory_format=torch.channels_last)\n",
    "            data[2] = data[2].to('cuda')\n",
    "            \n",
    "            \n",
    "            loss, step_metrics = training_step(data, online, target, temporal_ensembling)\n",
    "            opt.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            schedule.step()\n",
    "            scaler.update()\n",
    "\n",
    "            update_target_params(online.network.parameters(), target.network.parameters(), .99)\n",
    "            update_target_params(online.projector.parameters(), target.projector.parameters(), .99)\n",
    "                \n",
    "        total_loss += loss\n",
    "        for key in step_metrics:\n",
    "            metrics[key] += step_metrics[key]\n",
    "\n",
    "    print(e, time.time() - now, total_loss / (i_+1), metrics['byol_loss'] / (i_+1), \n",
    "          metrics['online_acc1'] / 50000, metrics['target_acc1'] / 50000)\n",
    "    if log:\n",
    "        i_ += 1\n",
    "        for key in metrics:\n",
    "            if key[-4:-1] == 'acc':\n",
    "                metrics[key] = metrics[key] / 50000\n",
    "            else:\n",
    "                metrics[key] = metrics[key]/i_\n",
    "        wandb.log(metrics)\n",
    "    checkpoint = {\n",
    "    'online': online.state_dict(),\n",
    "    'target': target.state_dict(),\n",
    "    'epoch': e,\n",
    "    'optimizer': opt.optim.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, 'checkpoint.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(online.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ae08a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
