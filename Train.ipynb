{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df9afd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook BYOL.ipynb to script\n",
      "[NbConvertApp] Writing 2969 bytes to BYOL.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script BYOL.ipynb\n",
    "import BYOL\n",
    "import torch\n",
    "import time\n",
    "from pretrain_dataloader import *\n",
    "from lars import LARSWrapper\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.enabled = True\n",
    "import copy\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b3f093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class args:\n",
    "    def __init__(self):\n",
    "        return\n",
    "args = args()\n",
    "\n",
    "args.dataset = 'cifar100'\n",
    "args.transform_kwargs=[{'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.2, 'hue': 0.1, 'color_jitter_prob': 0.8, 'gray_scale_prob': 0.2, 'horizontal_flip_prob': 0.5, 'gaussian_prob': 1.0, 'solarization_prob': 0.0, 'crop_size': 32, 'min_scale': 0.08, 'max_scale': 1.0}, {'brightness': 0.4, 'contrast': 0.4, 'saturation': 0.2, 'hue': 0.1, 'color_jitter_prob': 0.8, 'gray_scale_prob': 0.2, 'horizontal_flip_prob': 0.5, 'gaussian_prob': 0.1, 'solarization_prob': 0.2, 'crop_size': 32, 'min_scale': 0.08, 'max_scale': 1.0}]\n",
    "# asymmetric augmentations\n",
    "args.num_crops_per_aug = [1, 1]\n",
    "args.batch_size = 256\n",
    "args.num_workers = 4\n",
    "\n",
    "\n",
    "transform = [\n",
    "    prepare_transform(args.dataset, **kwargs) for kwargs in args.transform_kwargs\n",
    "]\n",
    "\n",
    "transform = prepare_n_crop_transform(transform, num_crops_per_aug=args.num_crops_per_aug)\n",
    "\n",
    "train_dataset = prepare_datasets(\n",
    "    args.dataset,\n",
    "    transform,\n",
    "    no_labels=False,\n",
    ")\n",
    "train_loader = prepare_dataloader(\n",
    "    train_dataset, batch_size=args.batch_size, num_workers=args.num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942feb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target_params(online_params, target_params, tau):\n",
    "\n",
    "    #update the backbone first\n",
    "    for op, mp in zip(online_params, target_params):\n",
    "        mp.data = tau * mp.data + (1 - tau) * op.data\n",
    "    \n",
    "def byol_loss_func(p: torch.Tensor, z: torch.Tensor, simplified: bool = True) -> torch.Tensor:\n",
    "    return 2 - 2 * F.cosine_similarity(p, z.detach(), dim=-1).mean()\n",
    "\n",
    "online = BYOL.BYOL_module().to('cuda').to(memory_format=torch.channels_last)\n",
    "target = copy.deepcopy(online).to('cuda').to(memory_format=torch.channels_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ee4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.optimizer = 'LARS'\n",
    "args.lr = .3\n",
    "args.weight_decay = 1.5e-6\n",
    "args.momentum = .9\n",
    "args.classifier_lr = .1\n",
    "args.classifier_weight_decay = 0\n",
    "args.epochs = 200\n",
    "args.warmup_epochs = 10\n",
    "args.steps = int((50000/args.batch_size) * args.epochs)\n",
    "args.warmup_steps = int((50000/args.batch_size) * args.warmup_epochs)\n",
    "\n",
    "params = [\n",
    "            {\"name\": \"backbone\", \"params\": online.network.parameters()},\n",
    "            {\n",
    "                \"name\": \"classifier\",\n",
    "                \"params\": online.classifier.parameters(),\n",
    "                \"lr\": args.classifier_lr,\n",
    "                \"weight_decay\": args.classifier_weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"momentum_classifier\",\n",
    "                \"params\": target.classifier.parameters(),\n",
    "                \"lr\": args.classifier_lr,\n",
    "                \"weight_decay\": args.classifier_weight_decay,\n",
    "            },\n",
    "            {'params': online.projector.parameters()},\n",
    "            {'params':online.predictor.parameters(),}\n",
    "        ]\n",
    "\n",
    "\n",
    "opt = torch.optim.SGD(params, lr = .3, weight_decay = 1.5e-5, momentum = .9)\n",
    "opt = LARSWrapper(opt, clip = True, exclude_bias_n_norm = True, eta = .001)\n",
    "schedule = LinearWarmupCosineAnnealingLR(\n",
    "                    opt,\n",
    "                    warmup_epochs= 10 * 195,\n",
    "                    max_epochs= 195 * 200,\n",
    "                    warmup_start_lr=3e-05,\n",
    "                    eta_min=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817d2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(data, online, target):\n",
    "    step_metrics = {}\n",
    "    \n",
    "    online1 = online(data[1][0])\n",
    "    online2 = online(data[1][1])\n",
    "    target1 = target.momentum_forward(data[1][0])\n",
    "    target2 = target.momentum_forward(data[1][1])\n",
    "    \n",
    "    #byol_loss\n",
    "    step_metrics[\"byol_loss\"] = byol_loss_func(online1['p'], target2['z'])\n",
    "    step_metrics[\"byol_loss\"] += byol_loss_func(online2['p'], target1['z'])\n",
    "    \n",
    "    #cross entropy loss\n",
    "    step_metrics[\"online_cross_entropy_loss\"] = F.cross_entropy(online1['logits'], data[2], ignore_index=-1)\n",
    "    step_metrics[\"momentum_cross_entropy_loss\"] = F.cross_entropy(target1['logits'], data[2], ignore_index=-1)\n",
    "    \n",
    "    #accuracy of predictions\n",
    "    _, predicted = torch.max(online1['logits'], 1)\n",
    "    step_metrics[\"online_acc1\"] = (predicted == data[2]).sum()\n",
    "    _, predicted = torch.max(target1['logits'], 1)\n",
    "    step_metrics[\"target_acc1\"] = (predicted == data[2]).sum()\n",
    "    \n",
    "    _, pred = online1['logits'].topk(5)\n",
    "    data[2] = data[2].unsqueeze(1).expand_as(pred)\n",
    "    step_metrics[\"online_acc5\"] = (data[2] == pred).any(dim = 1).sum()\n",
    "    _, pred = target1['logits'].topk(5)\n",
    "    step_metrics[\"target_acc5\"] = (data[2] == pred).any(dim = 1).sum()\n",
    "                   \n",
    "        \n",
    "    \n",
    "    \n",
    "    #metrics to track\n",
    "    with torch.no_grad():\n",
    "        cross_entropy = F.cross_entropy(online1['p'], target2['z'], ignore_index=-1) + F.cross_entropy(online2['p'], target1['z'], ignore_index=-1)\n",
    "        l1_dist = F.l1_loss(online1['p'], target2['z']) + F.l1_loss(online2['p'], target1['z'])\n",
    "        l2_dist = F.mse_loss(online1['p'], target2['z']) + F.mse_loss(online2['p'], target1['z'])\n",
    "        smooth_l1 = F.smooth_l1_loss(online1['p'], target2['z']) + F.smooth_l1_loss(online2['p'], target1['z'])\n",
    "        kl_div = F.kl_div(online1['p'], target2['z']) + F.kl_div(online2['p'], target1['z'])\n",
    "\n",
    "        representation_l1 = F.l1_loss(online1['Representation'], target2['Representation']) + F.l1_loss(online2['Representation'], target1['Representation'])\n",
    "        representation_l2 = F.mse_loss(online1['Representation'], target2['Representation']) + F.mse_loss(online2['Representation'], target1['Representation'])\n",
    "        representation_cross_entropy = F.cross_entropy(online1['Representation'], target2['Representation'], ignore_index=-1) + F.cross_entropy(online2['Representation'], target1['Representation'], ignore_index=-1)\n",
    "        representation_kl = F.kl_div(online1['Representation'], target2['Representation']) + F.kl_div(online2['Representation'], target1['Representation'])\n",
    "        representation_cos_sim = F.cosine_similarity(online1['Representation'], target2['Representation']) + F.cosine_similarity(online2['Representation'], target1['Representation'])\n",
    "\n",
    "        projection_l1 = F.l1_loss(online1['z'], target2['z']) + F.l1_loss(online2['z'], target1['z'])\n",
    "        projection_l2 = F.mse_loss(online1['z'], target2['z']) + F.mse_loss(online2['z'], target1['z'])\n",
    "        projection_cross_entropy = F.cross_entropy(online1['z'], target2['z'], ignore_index=-1) + F.cross_entropy(online2['z'], target1['z'], ignore_index=-1)\n",
    "        projection_kl = F.kl_div(online1['z'], target2['z']) + F.kl_div(online2['z'], target1['z'])\n",
    "        projection_cos_sim = F.cosine_similarity(online1['z'], target2['z']) + F.cosine_similarity(online2['z'], target1['z'])\n",
    "\n",
    "        momentum_projection_cos_sim = F.cosine_similarity(target1['z'], target2['z'])\n",
    "        momentum_representation_cos_sim = F.cosine_similarity(target1['Representation'], target2['Representation'])\n",
    "        momentum_representation_l2 =  F.mse_loss(target1['Representation'], target2['Representation'])\n",
    "        momentum_projection_l2 =  F.mse_loss(target1['z'], target2['z'])\n",
    "\n",
    "        online_projection_cos_sim = F.cosine_similarity(online1['z'], online2['z'])\n",
    "        online_representation_cos_sim = F.cosine_similarity(online1['Representation'], online2['Representation'])\n",
    "        online_representation_l2 =  F.mse_loss(online1['Representation'], online2['Representation'])\n",
    "        online_projection_l2 =  F.mse_loss(online1['z'], online2['z'])\n",
    "\n",
    "        step_metrics.update({\n",
    "            \"train_feats_cross_entropy\": cross_entropy,\n",
    "            \"train_feats_l1_dist\": l1_dist,\n",
    "            \"train_feats_l2_dist\": l2_dist,\n",
    "            \"train_feats_smooth_l1\": smooth_l1,\n",
    "            \"train_feats_kl_div\": kl_div,\n",
    "            \"representation_l1\": representation_l1,\n",
    "            \"representation_l2\": representation_l1,\n",
    "            \"representation_cross_entropy\": representation_cross_entropy,\n",
    "            \"representation_kl\": representation_kl,\n",
    "            \"representation_cos_sim\": representation_cos_sim.mean(),\n",
    "            \"projection_l1\": projection_l1,\n",
    "            \"projection_l2\": projection_l2,\n",
    "            \"projection_cross_entropy\": projection_cross_entropy,\n",
    "            \"projection_kl\": projection_kl,\n",
    "            \"projection_cos_sim\": projection_cos_sim.mean(),\n",
    "            \"momentum_projection_cos_sim\": momentum_projection_cos_sim.mean(),\n",
    "            \"momentum_representation_cos_sim\": momentum_representation_cos_sim.mean(),\n",
    "            \"momentum_representation_l2\": momentum_representation_l2,\n",
    "            \"momentum_representation_l2\": momentum_projection_l2,\n",
    "            \"online_projection_cos_sim\": online_projection_cos_sim.mean(),\n",
    "            \"online_representation_cos_sim\": online_representation_cos_sim.mean(),\n",
    "            \"online_representation_l2\": online_representation_l2,\n",
    "            \"online_projection_l2\": online_projection_l2,\n",
    "            })\n",
    "    return step_metrics[\"byol_loss\"] + step_metrics[\"online_cross_entropy_loss\"] + \\\n",
    "            step_metrics[\"momentum_cross_entropy_loss\"], step_metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bfd586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdcaustin33\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/da2986/custom_byol/wandb/run-20220418_163135-16h199qs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dcaustin33/custom_byol/runs/16h199qs\" target=\"_blank\">wise-glade-24</a></strong> to <a href=\"https://wandb.ai/dcaustin33/custom_byol\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log = True\n",
    "if log:\n",
    "    wandb.init(config = args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed5e40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da2986/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:2747: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 54.94324517250061 tensor(10.7328, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.5949, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0203, device='cuda:0') tensor(0.0180, device='cuda:0')\n",
      "1 54.69605827331543 tensor(10.0428, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.1775, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0374, device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "2 54.707274198532104 tensor(9.6586, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.0389, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0513, device='cuda:0') tensor(0.0488, device='cuda:0')\n",
      "3 54.75790047645569 tensor(9.4311, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.0009, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0640, device='cuda:0') tensor(0.0632, device='cuda:0')\n",
      "4 55.11026906967163 tensor(9.2865, device='cuda:0', grad_fn=<DivBackward0>) tensor(1.0109, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0714, device='cuda:0') tensor(0.0716, device='cuda:0')\n",
      "5 54.93128561973572 tensor(9.1220, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.9941, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0843, device='cuda:0') tensor(0.0842, device='cuda:0')\n",
      "6 54.51265835762024 tensor(8.9919, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.9670, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0897, device='cuda:0') tensor(0.0893, device='cuda:0')\n",
      "7 53.92320799827576 tensor(8.8288, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.9293, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.0983, device='cuda:0') tensor(0.0989, device='cuda:0')\n",
      "8 54.44942879676819 tensor(8.6859, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.9003, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1092, device='cuda:0') tensor(0.1106, device='cuda:0')\n",
      "9 54.490617513656616 tensor(8.5743, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.8907, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1161, device='cuda:0') tensor(0.1172, device='cuda:0')\n",
      "10 54.67635178565979 tensor(8.4772, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.8821, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1242, device='cuda:0') tensor(0.1270, device='cuda:0')\n",
      "11 54.776021003723145 tensor(8.3657, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.8731, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1305, device='cuda:0') tensor(0.1321, device='cuda:0')\n",
      "12 54.27716851234436 tensor(8.2625, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.8478, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1366, device='cuda:0') tensor(0.1390, device='cuda:0')\n",
      "13 54.333361864089966 tensor(8.1301, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.8220, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1480, device='cuda:0') tensor(0.1513, device='cuda:0')\n",
      "14 54.31340146064758 tensor(8.0084, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7880, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1542, device='cuda:0') tensor(0.1568, device='cuda:0')\n",
      "15 54.29729080200195 tensor(7.8919, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7730, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1639, device='cuda:0') tensor(0.1649, device='cuda:0')\n",
      "16 54.30412411689758 tensor(7.7741, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7527, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1692, device='cuda:0') tensor(0.1716, device='cuda:0')\n",
      "17 53.78675937652588 tensor(7.6640, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7367, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1784, device='cuda:0') tensor(0.1821, device='cuda:0')\n",
      "18 54.008039474487305 tensor(7.5775, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7386, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1867, device='cuda:0') tensor(0.1888, device='cuda:0')\n",
      "19 54.120625734329224 tensor(7.4903, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7326, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.1913, device='cuda:0') tensor(0.1950, device='cuda:0')\n",
      "20 54.347439765930176 tensor(7.3935, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7291, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2013, device='cuda:0') tensor(0.2046, device='cuda:0')\n",
      "21 54.10903334617615 tensor(7.3046, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7220, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2060, device='cuda:0') tensor(0.2099, device='cuda:0')\n",
      "22 54.15057849884033 tensor(7.2307, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7148, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2145, device='cuda:0') tensor(0.2188, device='cuda:0')\n",
      "23 54.332544565200806 tensor(7.1582, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7057, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2186, device='cuda:0') tensor(0.2232, device='cuda:0')\n",
      "24 54.288721323013306 tensor(7.0880, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7022, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2225, device='cuda:0') tensor(0.2282, device='cuda:0')\n",
      "25 54.20750665664673 tensor(7.0357, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7030, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2272, device='cuda:0') tensor(0.2330, device='cuda:0')\n",
      "26 54.2318274974823 tensor(6.9723, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7060, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2349, device='cuda:0') tensor(0.2426, device='cuda:0')\n",
      "27 54.035151720047 tensor(6.9078, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6996, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2418, device='cuda:0') tensor(0.2468, device='cuda:0')\n",
      "28 53.87830996513367 tensor(6.8290, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2451, device='cuda:0') tensor(0.2516, device='cuda:0')\n",
      "29 54.273216009140015 tensor(6.7951, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6970, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2504, device='cuda:0') tensor(0.2574, device='cuda:0')\n",
      "30 54.28240633010864 tensor(6.7430, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6973, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2569, device='cuda:0') tensor(0.2638, device='cuda:0')\n",
      "31 54.17526292800903 tensor(6.6920, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7026, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2616, device='cuda:0') tensor(0.2681, device='cuda:0')\n",
      "32 54.281797885894775 tensor(6.6392, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.7042, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2631, device='cuda:0') tensor(0.2696, device='cuda:0')\n",
      "33 54.18029832839966 tensor(6.5992, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6978, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2684, device='cuda:0') tensor(0.2763, device='cuda:0')\n",
      "34 54.17040801048279 tensor(6.5325, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6880, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2723, device='cuda:0') tensor(0.2787, device='cuda:0')\n",
      "35 54.20273518562317 tensor(6.5073, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6857, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2761, device='cuda:0') tensor(0.2825, device='cuda:0')\n",
      "36 54.20252442359924 tensor(6.4583, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6901, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2806, device='cuda:0') tensor(0.2899, device='cuda:0')\n",
      "37 54.07094883918762 tensor(6.4189, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6915, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2834, device='cuda:0') tensor(0.2905, device='cuda:0')\n",
      "38 53.76146841049194 tensor(6.3723, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2892, device='cuda:0') tensor(0.2970, device='cuda:0')\n",
      "39 54.604533195495605 tensor(6.3217, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6892, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.2952, device='cuda:0') tensor(0.3023, device='cuda:0')\n",
      "40 54.22031354904175 tensor(6.2881, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3004, device='cuda:0') tensor(0.3071, device='cuda:0')\n",
      "41 54.1430025100708 tensor(6.2514, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6843, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3000, device='cuda:0') tensor(0.3091, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 54.20474076271057 tensor(6.2315, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6845, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3036, device='cuda:0') tensor(0.3120, device='cuda:0')\n",
      "43 54.12798762321472 tensor(6.1785, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6812, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3067, device='cuda:0') tensor(0.3157, device='cuda:0')\n",
      "44 54.32501578330994 tensor(6.1302, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6710, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3128, device='cuda:0') tensor(0.3208, device='cuda:0')\n",
      "45 54.31333541870117 tensor(6.1005, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6739, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3140, device='cuda:0') tensor(0.3225, device='cuda:0')\n",
      "46 54.365769386291504 tensor(6.0917, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3176, device='cuda:0') tensor(0.3240, device='cuda:0')\n",
      "47 54.26241755485535 tensor(6.0463, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6773, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3206, device='cuda:0') tensor(0.3291, device='cuda:0')\n",
      "48 54.01000642776489 tensor(6.0075, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6780, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3255, device='cuda:0') tensor(0.3345, device='cuda:0')\n",
      "49 53.787469148635864 tensor(5.9874, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6805, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3258, device='cuda:0') tensor(0.3339, device='cuda:0')\n",
      "50 54.19911766052246 tensor(5.9689, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6863, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3290, device='cuda:0') tensor(0.3376, device='cuda:0')\n",
      "51 54.21609139442444 tensor(5.9383, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6833, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3321, device='cuda:0') tensor(0.3401, device='cuda:0')\n",
      "52 54.18930697441101 tensor(5.8943, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6782, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3407, device='cuda:0') tensor(0.3488, device='cuda:0')\n",
      "53 54.27364230155945 tensor(5.8728, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6765, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3379, device='cuda:0') tensor(0.3470, device='cuda:0')\n",
      "54 54.130929708480835 tensor(5.8589, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6784, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3409, device='cuda:0') tensor(0.3505, device='cuda:0')\n",
      "55 54.12789344787598 tensor(5.8375, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6776, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3414, device='cuda:0') tensor(0.3507, device='cuda:0')\n",
      "56 54.32792901992798 tensor(5.8088, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6810, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3488, device='cuda:0') tensor(0.3555, device='cuda:0')\n",
      "57 54.23586630821228 tensor(5.7794, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6812, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3479, device='cuda:0') tensor(0.3558, device='cuda:0')\n",
      "58 54.1409547328949 tensor(5.7598, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6776, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3506, device='cuda:0') tensor(0.3602, device='cuda:0')\n",
      "59 53.804354190826416 tensor(5.7315, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6756, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3531, device='cuda:0') tensor(0.3618, device='cuda:0')\n",
      "60 54.69331908226013 tensor(5.7193, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6768, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3549, device='cuda:0') tensor(0.3632, device='cuda:0')\n",
      "61 54.18008065223694 tensor(5.6977, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6793, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3568, device='cuda:0') tensor(0.3676, device='cuda:0')\n",
      "62 54.22713589668274 tensor(5.6876, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6833, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3584, device='cuda:0') tensor(0.3668, device='cuda:0')\n",
      "63 54.26866054534912 tensor(5.6574, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3602, device='cuda:0') tensor(0.3700, device='cuda:0')\n",
      "64 54.0920193195343 tensor(5.6293, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6842, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3648, device='cuda:0') tensor(0.3745, device='cuda:0')\n",
      "65 54.137218952178955 tensor(5.6106, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6793, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3673, device='cuda:0') tensor(0.3753, device='cuda:0')\n",
      "66 54.30310010910034 tensor(5.5863, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6789, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3681, device='cuda:0') tensor(0.3775, device='cuda:0')\n",
      "67 54.09873580932617 tensor(5.5519, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6722, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3724, device='cuda:0') tensor(0.3805, device='cuda:0')\n",
      "68 54.2464599609375 tensor(5.5405, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6790, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3728, device='cuda:0') tensor(0.3823, device='cuda:0')\n",
      "69 53.81584668159485 tensor(5.5006, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3775, device='cuda:0') tensor(0.3866, device='cuda:0')\n",
      "70 54.71928262710571 tensor(5.4947, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6773, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3779, device='cuda:0') tensor(0.3865, device='cuda:0')\n",
      "71 54.22399950027466 tensor(5.4920, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6778, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3772, device='cuda:0') tensor(0.3880, device='cuda:0')\n",
      "72 54.262859582901 tensor(5.4691, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6796, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3815, device='cuda:0') tensor(0.3927, device='cuda:0')\n",
      "73 54.09528064727783 tensor(5.4398, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6775, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3854, device='cuda:0') tensor(0.3958, device='cuda:0')\n",
      "74 54.268635749816895 tensor(5.4227, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6829, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3859, device='cuda:0') tensor(0.3964, device='cuda:0')\n",
      "75 54.167231798172 tensor(5.4023, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6816, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3882, device='cuda:0') tensor(0.3981, device='cuda:0')\n",
      "76 54.15486168861389 tensor(5.3950, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6806, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3902, device='cuda:0') tensor(0.4009, device='cuda:0')\n",
      "77 54.32979655265808 tensor(5.4024, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6917, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3891, device='cuda:0') tensor(0.3983, device='cuda:0')\n",
      "78 54.021228313446045 tensor(5.3709, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6883, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3928, device='cuda:0') tensor(0.4028, device='cuda:0')\n",
      "79 53.86741924285889 tensor(5.3594, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6882, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3946, device='cuda:0') tensor(0.4018, device='cuda:0')\n",
      "80 53.77797079086304 tensor(5.3459, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6835, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3937, device='cuda:0') tensor(0.4025, device='cuda:0')\n",
      "81 54.166125535964966 tensor(5.3135, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6848, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3972, device='cuda:0') tensor(0.4054, device='cuda:0')\n",
      "82 54.17283892631531 tensor(5.3269, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6926, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.3975, device='cuda:0') tensor(0.4061, device='cuda:0')\n",
      "83 54.10866141319275 tensor(5.2777, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6904, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4037, device='cuda:0') tensor(0.4128, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 54.16388511657715 tensor(5.2769, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4039, device='cuda:0') tensor(0.4136, device='cuda:0')\n",
      "85 54.40089130401611 tensor(5.2374, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6846, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4089, device='cuda:0') tensor(0.4173, device='cuda:0')\n",
      "86 54.21867513656616 tensor(5.2543, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6886, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4069, device='cuda:0') tensor(0.4146, device='cuda:0')\n",
      "87 54.2116060256958 tensor(5.2456, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6869, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4047, device='cuda:0') tensor(0.4135, device='cuda:0')\n",
      "88 54.39958906173706 tensor(5.2041, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6831, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4130, device='cuda:0') tensor(0.4209, device='cuda:0')\n",
      "89 54.378926515579224 tensor(5.1917, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6883, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4129, device='cuda:0') tensor(0.4211, device='cuda:0')\n",
      "90 54.0311644077301 tensor(5.1984, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6880, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4114, device='cuda:0') tensor(0.4207, device='cuda:0')\n",
      "91 54.693867921829224 tensor(5.1802, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6835, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4122, device='cuda:0') tensor(0.4209, device='cuda:0')\n",
      "92 54.00252318382263 tensor(5.1623, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6838, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4166, device='cuda:0') tensor(0.4238, device='cuda:0')\n",
      "93 54.21341347694397 tensor(5.1297, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4205, device='cuda:0') tensor(0.4286, device='cuda:0')\n",
      "94 54.2214412689209 tensor(5.1338, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6853, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4188, device='cuda:0') tensor(0.4277, device='cuda:0')\n",
      "95 54.1525342464447 tensor(5.1143, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6850, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4230, device='cuda:0') tensor(0.4310, device='cuda:0')\n",
      "96 53.99734139442444 tensor(5.1083, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6851, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4200, device='cuda:0') tensor(0.4276, device='cuda:0')\n",
      "97 54.073086738586426 tensor(5.0844, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6833, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4228, device='cuda:0') tensor(0.4307, device='cuda:0')\n",
      "98 54.05353808403015 tensor(5.0699, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6789, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4268, device='cuda:0') tensor(0.4349, device='cuda:0')\n",
      "99 54.30993342399597 tensor(5.0378, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6763, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4286, device='cuda:0') tensor(0.4355, device='cuda:0')\n",
      "100 53.75915312767029 tensor(5.0502, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6798, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4293, device='cuda:0') tensor(0.4377, device='cuda:0')\n",
      "101 54.369428873062134 tensor(5.0434, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6780, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4297, device='cuda:0') tensor(0.4388, device='cuda:0')\n",
      "102 54.18002986907959 tensor(5.0394, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6795, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4269, device='cuda:0') tensor(0.4350, device='cuda:0')\n",
      "103 54.17043924331665 tensor(5.0148, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6847, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4335, device='cuda:0') tensor(0.4402, device='cuda:0')\n",
      "104 54.206618547439575 tensor(5.0115, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6848, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4335, device='cuda:0') tensor(0.4399, device='cuda:0')\n",
      "105 54.1521942615509 tensor(4.9811, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6883, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4339, device='cuda:0') tensor(0.4446, device='cuda:0')\n",
      "106 54.23877811431885 tensor(4.9832, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6855, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4336, device='cuda:0') tensor(0.4419, device='cuda:0')\n",
      "107 54.05197858810425 tensor(4.9750, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6840, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4342, device='cuda:0') tensor(0.4420, device='cuda:0')\n",
      "108 54.07257556915283 tensor(4.9626, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6808, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4381, device='cuda:0') tensor(0.4470, device='cuda:0')\n",
      "109 54.247283697128296 tensor(4.9473, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6775, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4402, device='cuda:0') tensor(0.4479, device='cuda:0')\n",
      "110 53.79121708869934 tensor(4.9261, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6785, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4412, device='cuda:0') tensor(0.4494, device='cuda:0')\n",
      "111 53.74172067642212 tensor(4.9200, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6802, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4412, device='cuda:0') tensor(0.4478, device='cuda:0')\n",
      "112 54.17492651939392 tensor(4.9103, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6798, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4450, device='cuda:0') tensor(0.4525, device='cuda:0')\n",
      "113 54.10792851448059 tensor(4.9122, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6844, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4452, device='cuda:0') tensor(0.4530, device='cuda:0')\n",
      "114 54.11142110824585 tensor(4.8984, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6855, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4451, device='cuda:0') tensor(0.4544, device='cuda:0')\n",
      "115 54.1661171913147 tensor(4.8886, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6820, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4460, device='cuda:0') tensor(0.4531, device='cuda:0')\n",
      "116 54.11785173416138 tensor(4.8906, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6806, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4467, device='cuda:0') tensor(0.4538, device='cuda:0')\n",
      "117 53.91819643974304 tensor(4.8720, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6802, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4488, device='cuda:0') tensor(0.4542, device='cuda:0')\n",
      "118 53.998472690582275 tensor(4.8455, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6868, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4507, device='cuda:0') tensor(0.4575, device='cuda:0')\n",
      "119 54.11585259437561 tensor(4.8680, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6886, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4492, device='cuda:0') tensor(0.4573, device='cuda:0')\n",
      "120 53.94035816192627 tensor(4.8408, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6858, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4521, device='cuda:0') tensor(0.4598, device='cuda:0')\n",
      "121 53.77276825904846 tensor(4.8352, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6810, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4532, device='cuda:0') tensor(0.4582, device='cuda:0')\n",
      "122 54.10361409187317 tensor(4.8217, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6779, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4576, device='cuda:0') tensor(0.4628, device='cuda:0')\n",
      "123 54.13460826873779 tensor(4.7983, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6780, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4569, device='cuda:0') tensor(0.4626, device='cuda:0')\n",
      "124 54.061620473861694 tensor(4.7925, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6802, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4577, device='cuda:0') tensor(0.4630, device='cuda:0')\n",
      "125 54.08853268623352 tensor(4.8095, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4555, device='cuda:0') tensor(0.4629, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 54.13011574745178 tensor(4.7807, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6787, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4603, device='cuda:0') tensor(0.4664, device='cuda:0')\n",
      "127 54.206645250320435 tensor(4.7978, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6790, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4600, device='cuda:0') tensor(0.4643, device='cuda:0')\n",
      "128 54.152130365371704 tensor(4.7566, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6744, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4606, device='cuda:0') tensor(0.4666, device='cuda:0')\n",
      "129 53.99315905570984 tensor(4.7634, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6759, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4597, device='cuda:0') tensor(0.4662, device='cuda:0')\n",
      "130 54.014474391937256 tensor(4.7365, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6732, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4622, device='cuda:0') tensor(0.4699, device='cuda:0')\n",
      "131 53.708457231521606 tensor(4.7117, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6707, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4642, device='cuda:0') tensor(0.4713, device='cuda:0')\n",
      "132 54.23303580284119 tensor(4.7165, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6755, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4686, device='cuda:0') tensor(0.4744, device='cuda:0')\n",
      "133 54.01635265350342 tensor(4.6997, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6777, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4722, device='cuda:0') tensor(0.4756, device='cuda:0')\n",
      "134 54.266051054000854 tensor(4.6687, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6734, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4711, device='cuda:0') tensor(0.4768, device='cuda:0')\n",
      "135 54.02827191352844 tensor(4.6686, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6730, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4722, device='cuda:0') tensor(0.4791, device='cuda:0')\n",
      "136 54.140018463134766 tensor(4.6655, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6752, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4715, device='cuda:0') tensor(0.4763, device='cuda:0')\n",
      "137 54.183645248413086 tensor(4.6504, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6701, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4753, device='cuda:0') tensor(0.4811, device='cuda:0')\n",
      "138 54.15798616409302 tensor(4.6368, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6717, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4747, device='cuda:0') tensor(0.4799, device='cuda:0')\n",
      "139 54.26260185241699 tensor(4.6294, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6680, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4759, device='cuda:0') tensor(0.4803, device='cuda:0')\n",
      "140 53.941534996032715 tensor(4.6227, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6728, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4767, device='cuda:0') tensor(0.4821, device='cuda:0')\n",
      "141 53.85337805747986 tensor(4.5970, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6683, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4819, device='cuda:0') tensor(0.4867, device='cuda:0')\n",
      "142 54.648409366607666 tensor(4.5907, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6691, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4798, device='cuda:0') tensor(0.4858, device='cuda:0')\n",
      "143 54.17902159690857 tensor(4.5837, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6685, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4820, device='cuda:0') tensor(0.4865, device='cuda:0')\n",
      "144 54.01856231689453 tensor(4.5939, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6686, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4827, device='cuda:0') tensor(0.4872, device='cuda:0')\n",
      "145 54.112770318984985 tensor(4.5592, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6686, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4839, device='cuda:0') tensor(0.4884, device='cuda:0')\n",
      "146 54.085237979888916 tensor(4.5333, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6652, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4880, device='cuda:0') tensor(0.4916, device='cuda:0')\n",
      "147 53.92044711112976 tensor(4.5378, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6654, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4874, device='cuda:0') tensor(0.4925, device='cuda:0')\n",
      "148 54.09044051170349 tensor(4.5453, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6614, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4837, device='cuda:0') tensor(0.4889, device='cuda:0')\n",
      "149 54.11173725128174 tensor(4.5388, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6633, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4869, device='cuda:0') tensor(0.4902, device='cuda:0')\n",
      "150 54.18701720237732 tensor(4.5359, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6651, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4879, device='cuda:0') tensor(0.4925, device='cuda:0')\n",
      "151 53.819923400878906 tensor(4.5193, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6660, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4906, device='cuda:0') tensor(0.4944, device='cuda:0')\n",
      "152 54.37827014923096 tensor(4.5137, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6642, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4902, device='cuda:0') tensor(0.4947, device='cuda:0')\n",
      "153 54.12077355384827 tensor(4.5005, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6621, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4890, device='cuda:0') tensor(0.4938, device='cuda:0')\n",
      "154 54.119296073913574 tensor(4.4832, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6654, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4946, device='cuda:0') tensor(0.4981, device='cuda:0')\n",
      "155 54.23170518875122 tensor(4.4809, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6642, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4939, device='cuda:0') tensor(0.4980, device='cuda:0')\n",
      "156 54.166015625 tensor(4.4771, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6652, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4946, device='cuda:0') tensor(0.4975, device='cuda:0')\n",
      "157 54.182743549346924 tensor(4.4673, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6662, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4972, device='cuda:0') tensor(0.5005, device='cuda:0')\n",
      "158 53.9144983291626 tensor(4.4722, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6668, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4952, device='cuda:0') tensor(0.4976, device='cuda:0')\n",
      "159 54.16073393821716 tensor(4.4550, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6614, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4981, device='cuda:0') tensor(0.5005, device='cuda:0')\n",
      "160 53.9590950012207 tensor(4.4599, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6662, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4992, device='cuda:0') tensor(0.5011, device='cuda:0')\n",
      "161 53.80228662490845 tensor(4.4574, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6661, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4973, device='cuda:0') tensor(0.5006, device='cuda:0')\n",
      "162 53.66736936569214 tensor(4.4372, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6628, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.4982, device='cuda:0') tensor(0.5012, device='cuda:0')\n",
      "163 54.174407958984375 tensor(4.4305, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6605, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5006, device='cuda:0') tensor(0.5033, device='cuda:0')\n",
      "164 54.07912993431091 tensor(4.4120, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6570, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5016, device='cuda:0') tensor(0.5034, device='cuda:0')\n",
      "165 54.0988290309906 tensor(4.4043, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6591, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5023, device='cuda:0') tensor(0.5038, device='cuda:0')\n",
      "166 54.181108474731445 tensor(4.3978, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5074, device='cuda:0') tensor(0.5082, device='cuda:0')\n",
      "167 54.10836124420166 tensor(4.4099, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6605, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5030, device='cuda:0') tensor(0.5055, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 54.15423130989075 tensor(4.3884, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6564, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5053, device='cuda:0') tensor(0.5059, device='cuda:0')\n",
      "169 54.04614615440369 tensor(4.3909, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6580, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5067, device='cuda:0') tensor(0.5083, device='cuda:0')\n",
      "170 54.12036108970642 tensor(4.4069, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6605, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5021, device='cuda:0') tensor(0.5038, device='cuda:0')\n",
      "171 53.828521728515625 tensor(4.3769, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6589, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5070, device='cuda:0') tensor(0.5079, device='cuda:0')\n",
      "172 53.66307210922241 tensor(4.3770, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6593, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5067, device='cuda:0') tensor(0.5084, device='cuda:0')\n",
      "173 54.019893169403076 tensor(4.4064, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6601, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5035, device='cuda:0') tensor(0.5051, device='cuda:0')\n",
      "174 54.110886335372925 tensor(4.3598, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6578, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5118, device='cuda:0') tensor(0.5132, device='cuda:0')\n",
      "175 54.20534896850586 tensor(4.3564, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6592, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5082, device='cuda:0') tensor(0.5093, device='cuda:0')\n",
      "176 54.20691394805908 tensor(4.3599, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6594, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5083, device='cuda:0') tensor(0.5087, device='cuda:0')\n",
      "177 54.16994857788086 tensor(4.3480, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6604, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5127, device='cuda:0') tensor(0.5130, device='cuda:0')\n",
      "178 54.10731816291809 tensor(4.3547, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6574, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5084, device='cuda:0') tensor(0.5098, device='cuda:0')\n",
      "179 54.165079832077026 tensor(4.3313, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6556, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5142, device='cuda:0') tensor(0.5154, device='cuda:0')\n",
      "180 54.108652114868164 tensor(4.3589, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6576, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5109, device='cuda:0') tensor(0.5117, device='cuda:0')\n",
      "181 54.20118451118469 tensor(4.3570, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6586, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5113, device='cuda:0') tensor(0.5126, device='cuda:0')\n",
      "182 53.7632372379303 tensor(4.3658, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6594, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5101, device='cuda:0') tensor(0.5109, device='cuda:0')\n",
      "183 54.46799969673157 tensor(4.3322, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6539, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5122, device='cuda:0') tensor(0.5123, device='cuda:0')\n",
      "184 53.93922448158264 tensor(4.3641, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6583, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5096, device='cuda:0') tensor(0.5109, device='cuda:0')\n",
      "185 53.99124836921692 tensor(4.3341, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6541, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5126, device='cuda:0') tensor(0.5132, device='cuda:0')\n",
      "186 54.195855379104614 tensor(4.3469, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6563, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5117, device='cuda:0') tensor(0.5132, device='cuda:0')\n",
      "187 54.0599639415741 tensor(4.3441, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6575, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5102, device='cuda:0') tensor(0.5103, device='cuda:0')\n",
      "188 54.00012683868408 tensor(4.3405, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6544, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5119, device='cuda:0') tensor(0.5112, device='cuda:0')\n",
      "189 54.17812418937683 tensor(4.3349, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6571, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5155, device='cuda:0') tensor(0.5156, device='cuda:0')\n",
      "190 54.16281461715698 tensor(4.3319, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6574, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5147, device='cuda:0') tensor(0.5140, device='cuda:0')\n",
      "191 54.087640047073364 tensor(4.3274, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6546, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5141, device='cuda:0') tensor(0.5140, device='cuda:0')\n",
      "192 53.67589831352234 tensor(4.3405, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6546, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5127, device='cuda:0') tensor(0.5128, device='cuda:0')\n",
      "193 54.596222162246704 tensor(4.3083, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6537, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5164, device='cuda:0') tensor(0.5170, device='cuda:0')\n",
      "194 54.10356020927429 tensor(4.2985, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6510, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5169, device='cuda:0') tensor(0.5170, device='cuda:0')\n",
      "195 53.98656415939331 tensor(4.3210, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6535, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5138, device='cuda:0') tensor(0.5142, device='cuda:0')\n",
      "196 54.20544934272766 tensor(4.3277, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6564, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5149, device='cuda:0') tensor(0.5151, device='cuda:0')\n",
      "197 54.286447286605835 tensor(4.3472, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6575, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5136, device='cuda:0') tensor(0.5142, device='cuda:0')\n",
      "198 54.24361848831177 tensor(4.3150, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6539, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5159, device='cuda:0') tensor(0.5159, device='cuda:0')\n",
      "199 54.1803514957428 tensor(4.3296, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.6597, device='cuda:0', grad_fn=<DivBackward0>) tensor(0.5157, device='cuda:0') tensor(0.5159, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for e in range(200):\n",
    "    metrics = {\n",
    "        \"byol_loss\": 0,\n",
    "        'online_cross_entropy_loss': 0,\n",
    "        'momentum_cross_entropy_loss': 0,\n",
    "        'online_acc1': 0,\n",
    "        'target_acc1': 0,\n",
    "        'online_acc5': 0,\n",
    "        'target_acc5': 0,\n",
    "        \"train_feats_cross_entropy\": 0,\n",
    "        \"train_feats_l1_dist\": 0,\n",
    "        \"train_feats_l2_dist\": 0,\n",
    "        \"train_feats_smooth_l1\": 0,\n",
    "        \"train_feats_kl_div\": 0,\n",
    "        \"representation_l1\": 0,\n",
    "        \"representation_l2\": 0,\n",
    "        \"representation_cross_entropy\": 0,\n",
    "        \"representation_kl\": 0,\n",
    "        \"representation_cos_sim\": 0,\n",
    "        \"projection_l1\": 0,\n",
    "        \"projection_l2\": 0,\n",
    "        \"projection_cross_entropy\": 0,\n",
    "        \"projection_kl\": 0,\n",
    "        \"projection_cos_sim\": 0,\n",
    "        \"momentum_projection_cos_sim\": 0,\n",
    "        \"momentum_representation_cos_sim\": 0,\n",
    "        \"momentum_representation_l2\": 0,\n",
    "        \"momentum_representation_l2\": 0,\n",
    "        \"online_projection_cos_sim\": 0,\n",
    "        \"online_representation_cos_sim\": 0,\n",
    "        \"online_representation_l2\": 0,\n",
    "        \"online_projection_l2\": 0,\n",
    "        }\n",
    "    total_loss = 0\n",
    "    now = time.time()\n",
    "    for i_, data in enumerate(train_loader):\n",
    "        \n",
    "        with torch.autocast('cuda'):\n",
    "            step += 1\n",
    "            data[0] = data[0].to('cuda')\n",
    "            data[1][0] = data[1][0].to('cuda').to(memory_format=torch.channels_last)\n",
    "            data[1][1] = data[1][1].to('cuda').to(memory_format=torch.channels_last)\n",
    "            data[2] = data[2].to('cuda')\n",
    "            \n",
    "            \n",
    "            loss, step_metrics = training_step(data, online, target)\n",
    "            opt.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            schedule.step()\n",
    "            scaler.update()\n",
    "\n",
    "            update_target_params(online.network.parameters(), target.network.parameters(), .99)\n",
    "            update_target_params(online.projector.parameters(), target.projector.parameters(), .99)\n",
    "                \n",
    "        total_loss += loss\n",
    "        for key in step_metrics:\n",
    "            metrics[key] += step_metrics[key]\n",
    "\n",
    "    print(e, time.time() - now, total_loss / (i_+1), metrics['byol_loss'] / (i_+1), \n",
    "          metrics['online_acc1'] / 50000, metrics['target_acc1'] / 50000)\n",
    "    if log:\n",
    "        i_ += 1\n",
    "        for key in metrics:\n",
    "            if key[-4:-1] == 'acc':\n",
    "                metrics[key] = metrics[key] / 50000\n",
    "            else:\n",
    "                metrics[key] = metrics[key]/i_\n",
    "        wandb.log(metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb0d0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
